{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5a6c66a-c330-459c-8fef-60cdd828fe95",
   "metadata": {},
   "source": [
    "**Please note that the 01_setup notebook should be executed before running this notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538e77f-4c17-446a-9896-9babea70b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, textwrap\n",
    "from icecream import ic\n",
    "# Get original notebook path and LD_LIBRARY_PATH\n",
    "notebook_path = ic(os.getcwd())\n",
    "original_ld_library_path = ic(os.environ.get('LD_LIBRARY_PATH'))\n",
    "# Software and install_prefix as defined in 01_setup.ipynb\n",
    "software_path = ic(os.path.join(notebook_path, 'sjk012', 'software'))\n",
    "install_prefix = ic(os.path.join(software_path, 'opt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3fdaaf-af24-4ab2-ae20-9eab8cb0f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the environment\n",
    "os.environ['LD_LIBRARY_PATH'] = os.path.join(install_prefix, 'blis', 'lib')\n",
    "os.environ['LD_LIBRARY_PATH'] += \":\"\n",
    "os.environ['LD_LIBRARY_PATH'] += os.path.join(install_prefix, 'openblas', 'lib')\n",
    "if original_ld_library_path is not None:\n",
    "    os.environ['LD_LIBRARY_PATH'] += \":\"\n",
    "    os.environ['LD_LIBRARY_PATH'] += original_ld_library_path\n",
    "_ = ic(os.environ['LD_LIBRARY_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03820adf-2f64-4b9d-9fa8-01d9eb9cb676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cell\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sjk012.classifiers.cnn import *\n",
    "from sjk012.data_utils import get_CIFAR10_data\n",
    "from sjk012.gradient_check import eval_numerical_gradient_array, eval_numerical_gradient\n",
    "from sjk012.layers import *\n",
    "# from sjk012.fast_layers import *\n",
    "from sjk012.solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Use pyximport to compile the cython modules\n",
    "import pyximport\n",
    "pyximport.install(reload_support=True, pyimport=True)\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bdd1a3-ae61-4539-bf55-832031cc926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the (preprocessed) CIFAR-10 data.\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in list(data.items()):\n",
    "    print(f\"{k}: {v.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eef73a4-5d8f-4c8f-b053-0e9259ce3416",
   "metadata": {},
   "source": [
    "# Convolutional \"Sandwich\" Layers\n",
    "In the previous assignment, we introduced the concept of \"sandwich\" layers that combine multiple operations into commonly used patterns. In the file `sjk012/layer_utils.py` you will find sandwich layers that implement a few commonly used patterns for convolutional networks. Run the cells below to sanity check their usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b134f5d-4f4b-4ad8-9b6d-fde33ae7c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sjk012.layer_utils import conv_relu_pool_forward, conv_relu_pool_backward\n",
    "from sjk012.gradient_check import *\n",
    "np.random.seed(12)\n",
    "x = np.random.randn(2, 3, 8, 8).astype(np.float32)\n",
    "w = np.random.randn(3, 3, 3, 3).astype(np.float32)\n",
    "b = np.random.randn(3,).astype(np.float32)\n",
    "dy = np.random.randn(2, 3, 4, 4).astype(np.float32)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2, 'padding': 0}\n",
    "\n",
    "y, cache = conv_relu_pool_forward(x, w, b, conv_param, pool_param)\n",
    "dx, dw, db = conv_relu_pool_backward(dy, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], x, dy, h=1e-3)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], w, dy, h=1e-3)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], b, dy, h=1e-3)\n",
    "\n",
    "# Relative errors should be around e-8 or less\n",
    "print('Testing conv_relu_pool')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809ff9ce-5dc7-4187-8493-29a6df428eb3",
   "metadata": {},
   "source": [
    "# Three-Layer Convolutional Network\n",
    "Now that you have implemented all the necessary layers, we can put them together into a simple convolutional network.\n",
    "\n",
    "Open the file `sjk012/classifiers/cnn.py` and complete the implementation of the `ThreeLayerConvNet` class. Remember you can use the fast/sandwich layers (already imported for you) in your implementation. Run the following cells to help you debug:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482c5199-3a53-4c60-b026-48d55bb87cd2",
   "metadata": {},
   "source": [
    "## Sanity Check Loss\n",
    "After you build a new network, one of the first things you should do is sanity check the loss. When we use the softmax loss, we expect the loss for random weights (and no regularization) to be about `log(C)` for `C` classes. When we add regularization the loss should go up slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f45e47-e330-4c9b-a380-802d3ab86734",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ThreeLayerConvNet()\n",
    "\n",
    "N = 50\n",
    "X = np.random.randn(N, 3, 32, 32).astype(np.float32)\n",
    "y = np.random.randint(10, size=N).astype(np.int8)\n",
    "\n",
    "loss, grads = model.loss(X, y)\n",
    "print('Initial loss (no regularization): ', loss)\n",
    "\n",
    "model.reg = 0.5\n",
    "loss, grads = model.loss(X, y)\n",
    "print('Initial loss (with regularization): ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf672e-34ee-4635-a065-31750b6986d4",
   "metadata": {},
   "source": [
    "## Gradient Check\n",
    "After the loss looks reasonable, use numeric gradient checking to make sure that your backward pass is correct. When you use numeric gradient checking you should use a small amount of artificial data and a small number of neurons at each layer. Note: correct implementations may still have relative errors up to the order of e-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d960c0c2-c8d2-4993-8f0b-e611db558c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "input_dim = (3, 8, 8)\n",
    "reg = 0.0\n",
    "num_classes = 10\n",
    "np.random.seed(12)\n",
    "X = np.random.randn(num_inputs, *input_dim).astype(np.float32)\n",
    "y = np.random.randint(num_classes, size=num_inputs).astype(np.int8)\n",
    "\n",
    "model = ThreeLayerConvNet(\n",
    "    num_filters=3,\n",
    "    filter_size=3,\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=5,\n",
    "    dtype=np.float32\n",
    ")\n",
    "loss, grads = model.loss(X, y)\n",
    "# Errors should be small, but correct implementations may have\n",
    "# relative errors up to the order of e-2\n",
    "for param_name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, model.params[param_name], verbose=False, h=1e-0)\n",
    "    e = rel_error(param_grad_num, grads[param_name])\n",
    "    print('%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name])), 'Allclose: ', np.allclose(param_grad_num, grads[param_name], atol=1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e639eb9-5eb9-42cc-8785-3a7063db8639",
   "metadata": {},
   "source": [
    "## Overfit Small Data\n",
    "A nice trick is to train your model with just a few training samples. You should be able to overfit small datasets, which will result in very high training accuracy and comparatively low validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cce81ce-50d0-4b11-a439-17ac9ad1fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "\n",
    "num_train = 100\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train].astype(np.float32),\n",
    "  'y_train': data['y_train'][:num_train].astype(np.int8),\n",
    "  'X_val': data['X_val'].astype(np.float32),\n",
    "  'y_val': data['y_val'].astype(np.int8),\n",
    "}\n",
    "\n",
    "model = ThreeLayerConvNet(dtype=np.float32)\n",
    "\n",
    "solver = Solver(\n",
    "    model,\n",
    "    small_data,\n",
    "    num_epochs=20,\n",
    "    batch_size=50,\n",
    "    update_rule='adam',\n",
    "    optim_config={'learning_rate': 1e-3,},\n",
    "    verbose=True,\n",
    "    print_every=1\n",
    ")\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa95ca3-b770-451a-b441-14b35f364ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final training accuracy.\n",
    "print(\n",
    "    \"Small data training accuracy:\",\n",
    "    solver.check_accuracy(small_data['X_train'], small_data['y_train'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4fcd93-9eb8-4058-a309-7fdc9b73cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final validation accuracy.\n",
    "print(\n",
    "    \"Small data validation accuracy:\",\n",
    "    solver.check_accuracy(small_data['X_val'], small_data['y_val'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c009aa-3b73-47d7-9c04-ff2ec7dd337d",
   "metadata": {},
   "source": [
    "Plotting the loss, training accuracy, and validation accuracy should show clear overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e26db57-7226-4a15-8456-0b97a6d95e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(solver.train_acc_history, '-o')\n",
    "plt.plot(solver.val_acc_history, '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291b70a-421b-4eae-a0b4-43b5736ae1bb",
   "metadata": {},
   "source": [
    "## Parallel Performance Evaluation: Analyzing Training Time with Different Number of Threads and Batch Sizes\n",
    "\n",
    "In this exercise, you will explore how the training time of a convolutional neural network (CNN) model varies with different numbers of threads and batch sizes. You will use the provided training code to train the model and measure the training time for various configurations.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. Load the provided dataset (`data`) and ensure it contains the necessary training and validation data.\n",
    "2. Implement the `train_model` function to train the CNN model using the specified number of threads and batch size. Use the provided training code as a reference.\n",
    "3. Set the right batch size to the solver (`batch_size`) to test.\n",
    "4. Measure the training time of the `train_model` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58057fef-7b30-41e3-b42c-163015dcf4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "# Define the training code\n",
    "def train_model(batch_size):\n",
    "    np.random.seed(12)\n",
    "\n",
    "    ###########################################################################\n",
    "    # TODO: Call the train model method and measure its training time         #\n",
    "    ###########################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################    \n",
    "    \n",
    "    return end_time - start_time\n",
    "\n",
    "# Define the number of threads and batch size configurations to test\n",
    "num_threads_list = [1, 4, 8, 16]\n",
    "batch_size_list = [16, 32, 64]\n",
    "\n",
    "# Measure the training time for each configuration\n",
    "training_times = np.zeros((len(num_threads_list), len(batch_size_list)))\n",
    "\n",
    "for i, n_threads in enumerate(num_threads_list):\n",
    "    with threadpool_limits(limits=n_threads):\n",
    "        for j, batch_size in enumerate(batch_size_list):\n",
    "            print('Testing training with %d threads and %d batch size' %(n_threads, batch_size))\n",
    "            training_time = train_model(batch_size)\n",
    "            training_times[i, j] = training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b2532e-cea1-4b9d-a64f-33b7a9b9f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training time for each batch size, with different lines for each number of threads\n",
    "plt.figure()\n",
    "for i, num_threads in enumerate(num_threads_list):\n",
    "    plt.plot(batch_size_list, training_times[i, :], marker='o', label=f'{num_threads} Threads')\n",
    "\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Training Time (seconds)')\n",
    "plt.title('Training Time vs. Batch Size (for different number of threads)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fad02f-2fdc-44d1-8b2b-7c547e4f5d4d",
   "metadata": {},
   "source": [
    "## Train the Network\n",
    "By training the three-layer convolutional network for one epoch, you should achieve greater than 40% accuracy on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020a4a35-c349-4538-a03d-a5019066f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ThreeLayerConvNet(weight_scale=0.001, hidden_dim=500, reg=0.001)\n",
    "\n",
    "all_data = {\n",
    "   'X_train': data['X_train'].astype(np.float32),\n",
    "   'y_train': data['y_train'].astype(np.int8),\n",
    "   'X_val': data['X_val'].astype(np.float32),\n",
    "   'y_val': data['y_val'].astype(np.int8),\n",
    "}\n",
    "\n",
    "solver = Solver(\n",
    "    model,\n",
    "    all_data,\n",
    "    num_epochs=1,\n",
    "    batch_size=50,\n",
    "    update_rule='adam',\n",
    "    optim_config={'learning_rate': 1e-3,},\n",
    "    verbose=True,\n",
    "    print_every=20\n",
    ")\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816dcf8-1892-4b5a-b4b3-acd5a8d3f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final training accuracy.\n",
    "print(\n",
    "    \"Full data training accuracy:\",\n",
    "    solver.check_accuracy(data['X_train'].astype(np.float32), data['y_train'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da5a91-ca24-4498-a5bf-1a299065a6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final validation accuracy.\n",
    "print(\n",
    "    \"Full data validation accuracy:\",\n",
    "    solver.check_accuracy(data['X_val'].astype(np.float32), data['y_val'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6253c04-f586-40ac-aaca-12f45e3ec34d",
   "metadata": {},
   "source": [
    "## Visualize Filters\n",
    "You can visualize the first-layer convolutional filters from the trained network by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f94a7bd-0d67-4b40-9019-7e2b0a1819ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sjk012.vis_utils import visualize_grid\n",
    "\n",
    "grid = visualize_grid(model.params['W1'].transpose(0, 2, 3, 1))\n",
    "plt.imshow(grid.astype('uint8'))\n",
    "plt.axis('off')\n",
    "plt.gcf().set_size_inches(7,7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb90f9-80a6-4eeb-b46d-065f34afee28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
