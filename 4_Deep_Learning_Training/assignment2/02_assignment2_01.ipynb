{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please note that the 01_setup notebook should be executed before running this notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| os.getcwd(): ('/home/vicentamen/Documents/Intelligent '\n",
      "                  'Systems/SKJ012-HighPerformanceML/4_Deep_Learning_Training/assignment2')\n",
      "ic| os.environ.get('LD_LIBRARY_PATH'): ('/home/vicentamen/Documents/Intelligent '\n",
      "                                        'Systems/SKJ012-HighPerformanceML/4_Deep_Learning_Training/assignment2/sjk012/software/opt/blis/lib:/home/vicentamen/Documents/Intelligent '\n",
      "                                        'Systems/SKJ012-HighPerformanceML/4_Deep_Learning_Training/assignment2/sjk012/software/opt/openblas/lib')\n",
      "ic| os.path.join(notebook_path, 'sjk012', 'software'): ('/home/vicentamen/Documents/Intelligent '\n",
      "                                                        'Systems/SKJ012-HighPerformanceML/4_Deep_Learning_Training/assignment2/sjk012/software')\n",
      "ic| os.path.join(software_path, 'opt'): ('/home/vicentamen/Documents/Intelligent '\n",
      "                                         'Systems/SKJ012-HighPerformanceML/4_Deep_Learning_Training/assignment2/sjk012/software/opt')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from icecream import ic\n",
    "# Get original notebook path and LD_LIBRARY_PATH\n",
    "notebook_path = ic(os.getcwd())\n",
    "original_ld_library_path = ic(os.environ.get('LD_LIBRARY_PATH'))\n",
    "# Software and install_prefix as defined in 01_setup.ipynb\n",
    "software_path = ic(os.path.join(notebook_path, 'sjk012', 'software'))\n",
    "install_prefix = ic(os.path.join(software_path, 'opt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| os.environ['LD_LIBRARY_PATH']: ('/home/vicentamen/Documents/Intelligent '\n",
      "                                    'Systems/SKJ012-HighPerformanceML/4_Deep_Learning_Training/assignment2/sjk012/software/opt/blis/lib:/home/vicentamen/Documents/Intelligent '\n",
      "                                    'Systems/SKJ012-HighPerformanceML/4_Deep_Learning_Training/assignment2/sjk012/software/opt/openblas/lib:/home/vicentamen/Documents/Intelligent '\n",
      "                                    'Systems/SKJ012-HighPerformanceML/4_Deep_Learning_Training/assignment2/sjk012/software/opt/blis/lib:/home/vicentamen/Documents/Intelligent '\n",
      "                                    'Systems/SKJ012-HighPerformanceML/4_Deep_Learning_Training/assignment2/sjk012/software/opt/openblas/lib')\n"
     ]
    }
   ],
   "source": [
    "# Update the environment\n",
    "os.environ['LD_LIBRARY_PATH'] = os.path.join(install_prefix, 'blis', 'lib')\n",
    "os.environ['LD_LIBRARY_PATH'] += \":\"\n",
    "os.environ['LD_LIBRARY_PATH'] += os.path.join(install_prefix, 'openblas', 'lib')\n",
    "if original_ld_library_path is not None:\n",
    "    os.environ['LD_LIBRARY_PATH'] += \":\"\n",
    "    os.environ['LD_LIBRARY_PATH'] += original_ld_library_path\n",
    "_ = ic(os.environ['LD_LIBRARY_PATH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7_7jlOfXdbq",
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# Convolutional Networks\n",
    "\n",
    "So far we have worked with  fully connected networks, using them to explore different optimization strategies and network architectures. Fully connected networks are a good testbed for experimentation because they are very computationally efficient, but in practice all state-of-the-art results use convolutional networks instead.\n",
    "\n",
    "First you will implement several layer types that are used in convolutional networks. You will then use these layers to train a convolutional network on the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3391,
     "status": "ok",
     "timestamp": 1629904167298,
     "user": {
      "displayName": "MANTAS BIRŠKUS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p74VzcLbLKZFYUnmVzxKmHhFZC9ouHcczEsEmQ=s64",
      "userId": "00995227095641424292"
     },
     "user_tz": -180
    },
    "id": "trzGFdRSXdbt",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Setup cell\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sjk012.classifiers.cnn import *\n",
    "from sjk012.data_utils import get_CIFAR10_data\n",
    "from sjk012.gradient_check import eval_numerical_gradient_array, eval_numerical_gradient\n",
    "from sjk012.layers import *\n",
    "# from sjk012.fast_layers import *\n",
    "from sjk012.solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14169,
     "status": "ok",
     "timestamp": 1629904184328,
     "user": {
      "displayName": "MANTAS BIRŠKUS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p74VzcLbLKZFYUnmVzxKmHhFZC9ouHcczEsEmQ=s64",
      "userId": "00995227095641424292"
     },
     "user_tz": -180
    },
    "id": "EKYZ4Sy_Xdbu",
    "outputId": "7ffc9927-4d20-4f5f-8a3f-0aac347e0b1e",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/vicentamen/Documents/Intelligent Systems/SKJ012-HighPerformanceML/4_Deep_Learning_Training/assignment2/sjk012/datasets/cifar-10-batches-py/data_batch_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the (preprocessed) CIFAR-10 data.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mget_CIFAR10_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(data\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Intelligent Systems/SKJ012-HighPerformanceML/4_Deep_Learning_Training/assignment2/sjk012/data_utils.py:59\u001b[0m, in \u001b[0;36mget_CIFAR10_data\u001b[0;34m(num_training, num_validation, num_test, subtract_mean)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Load the raw CIFAR-10 data\u001b[39;00m\n\u001b[1;32m     56\u001b[0m cifar10_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     57\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/cifar-10-batches-py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m )\n\u001b[0;32m---> 59\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mload_CIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcifar10_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Subsample the data\u001b[39;00m\n\u001b[1;32m     62\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(num_training, num_training \u001b[38;5;241m+\u001b[39m num_validation))\n",
      "File \u001b[0;32m~/Documents/Intelligent Systems/SKJ012-HighPerformanceML/4_Deep_Learning_Training/assignment2/sjk012/data_utils.py:37\u001b[0m, in \u001b[0;36mload_CIFAR10\u001b[0;34m(ROOT)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m):\n\u001b[1;32m     36\u001b[0m     f \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_batch_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (b,))\n\u001b[0;32m---> 37\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mload_CIFAR_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     xs\u001b[38;5;241m.\u001b[39mappend(X)\n\u001b[1;32m     39\u001b[0m     ys\u001b[38;5;241m.\u001b[39mappend(Y)\n",
      "File \u001b[0;32m~/Documents/Intelligent Systems/SKJ012-HighPerformanceML/4_Deep_Learning_Training/assignment2/sjk012/data_utils.py:22\u001b[0m, in \u001b[0;36mload_CIFAR_batch\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_CIFAR_batch\u001b[39m(filename):\n\u001b[1;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" load single batch of cifar \"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     23\u001b[0m         datadict \u001b[38;5;241m=\u001b[39m load_pickle(f)\n\u001b[1;32m     24\u001b[0m         X \u001b[38;5;241m=\u001b[39m datadict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/vicentamen/Documents/Intelligent Systems/SKJ012-HighPerformanceML/4_Deep_Learning_Training/assignment2/sjk012/datasets/cifar-10-batches-py/data_batch_1'"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR-10 data.\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in list(data.items()):\n",
    "    print(f\"{k}: {v.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2b63T_MXdbw"
   },
   "source": [
    "## Convolution: Naive Forward Pass\n",
    "\n",
    "![Convolution](sjk012/img/conv.jpg) \n",
    "\n",
    "The convolution operation lies at the heart of convolutional neural networks. To implement the forward pass for the convolutional layer, you'll use the function `conv_forward_numpy` within the file `sjk012/layers.py`. Don't concern yourself too much with efficiency at this stage; focus on writing clear and understandable code.\n",
    "\n",
    "### Forward Pass Formulas\n",
    "\n",
    "The forward pass of a convolutional layer involves the following computations:\n",
    "\n",
    "1. **Convolution operation**:\n",
    "\n",
    "$$O[k, i, j] = b[k] + \\sum_{c=0}^{C-1}  \\sum_{l=0}^{K_h-1} \\sum_{d=0}^{K_w-1} X[c, i+k, j+l] \\cdot F[k, c, l, d]$$\n",
    "\n",
    "Where:\n",
    "   - $ O[k, i, j] $ is the value at position $ (i, j) $ of the $ k $-th channel in the output feature map.\n",
    "   - $ K_h $ and $ K_w $ are the height and width of the filter, respectively.\n",
    "   - $ C $ is the number of channels in the input.\n",
    "   - $ X $ is the input tensor.\n",
    "   - $ F $ is the filter tensor.\n",
    "   - $ b $ is the bias tensor.\n",
    "\n",
    "Implement this calculation in the `conv_forward_numpy` function.\n",
    "\n",
    "### Testing Your Implementation\n",
    "\n",
    "After implementing the forward pass, you can test your implementation by running the following code. This will help ensure that your convolutional layer behaves as expected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1629904194271,
     "user": {
      "displayName": "MANTAS BIRŠKUS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p74VzcLbLKZFYUnmVzxKmHhFZC9ouHcczEsEmQ=s64",
      "userId": "00995227095641424292"
     },
     "user_tz": -180
    },
    "id": "Ug8itPHMXdbx",
    "outputId": "81624453-7044-4fc5-bf64-19c41011eaa3"
   },
   "outputs": [],
   "source": [
    "x_shape = (2, 3, 5, 5)\n",
    "w_shape = (3, 3, 3, 3)\n",
    "x = np.linspace(-0.1, 0.5, num=np.prod(x_shape), dtype=np.float32).reshape(x_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=np.prod(w_shape), dtype=np.float32).reshape(w_shape)\n",
    "b = np.linspace(-0.1, 0.2, num=3, dtype=np.float32)\n",
    "\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "out, _ = conv_forward_numpy(x, w, b, conv_param)\n",
    "correct_out = np.array([[[[-0.06974833, -0.06704278, -0.08701342],\n",
    "                          [-0.1167995 , -0.14790688, -0.1481334 ],\n",
    "                          [-0.16322148, -0.21268874, -0.1877349 ]],\n",
    "\n",
    "                         [[ 0.10607383,  0.14003775,  0.11327182],\n",
    "                          [ 0.1636703 ,  0.22531879,  0.16903104],\n",
    "                          [ 0.1349161 ,  0.17786492,  0.13486576]],\n",
    "\n",
    "                         [[ 0.281896  ,  0.34711832,  0.31355706],\n",
    "                          [ 0.44414014,  0.59854448,  0.48619545],\n",
    "                          [ 0.43305367,  0.56841862,  0.45746642]]],\n",
    "\n",
    "\n",
    "                        [[[-0.45481545, -0.6616317 , -0.49473158],\n",
    "                          [-0.74536496, -1.1162374 , -0.81067538],\n",
    "                          [-0.61624163, -0.90920722, -0.66340607]],\n",
    "\n",
    "                         [[ 0.3325839 ,  0.46281463,  0.31713089],\n",
    "                          [ 0.45247066,  0.63303697,  0.42385486],\n",
    "                          [ 0.29347315,  0.39871228,  0.27077183]],\n",
    "\n",
    "                         [[ 1.1199832 ,  1.58726108,  1.12899327],\n",
    "                          [ 1.65030622,  2.38231134,  1.65838516],\n",
    "                          [ 1.20318794,  1.70663178,  1.20494974]]]])\n",
    "\n",
    "# Compare your output to ours; difference should be around e-8\n",
    "print('Testing conv_forward_naive')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Faijxtr8Xdbz"
   },
   "source": [
    "## Aside: Image Processing via Convolutions\n",
    "\n",
    "As fun way to both check your implementation and gain a better understanding of the type of operation that convolutional layers can perform, we will set up an input containing two images and manually set up filters that perform common image processing operations (grayscale conversion and edge detection). The convolution forward pass will apply these operations to each of the input images. We can then visualize the results as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 1685,
     "status": "ok",
     "timestamp": 1629826100179,
     "user": {
      "displayName": "MANTAS BIRŠKUS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p74VzcLbLKZFYUnmVzxKmHhFZC9ouHcczEsEmQ=s64",
      "userId": "00995227095641424292"
     },
     "user_tz": -180
    },
    "id": "fHFCqsxAXdbz",
    "outputId": "1700d0b4-1298-47c0-c99c-91854aa9bf8f",
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "from imageio.v2 import imread\n",
    "from PIL import Image\n",
    "\n",
    "kitten = imread('sjk012/notebook_images/kitten.jpg')\n",
    "puppy = imread('sjk012/notebook_images/puppy.jpg')\n",
    "# kitten is wide, and puppy is already square\n",
    "d = kitten.shape[1] - kitten.shape[0]\n",
    "kitten_cropped = kitten[:, d//2:-d//2, :]\n",
    "\n",
    "img_size = 200   # Make this smaller if it runs too slow\n",
    "resized_puppy = np.array(Image.fromarray(puppy).resize((img_size, img_size)))\n",
    "resized_kitten = np.array(Image.fromarray(kitten_cropped).resize((img_size, img_size)))\n",
    "x = np.zeros((2, 3, img_size, img_size))\n",
    "x[0, :, :, :] = resized_puppy.transpose((2, 0, 1))\n",
    "x[1, :, :, :] = resized_kitten.transpose((2, 0, 1))\n",
    "\n",
    "# Set up a convolutional weights holding 2 filters, each 3x3\n",
    "w = np.zeros((2, 3, 3, 3))\n",
    "\n",
    "###########################################################################\n",
    "# TODO: The first filter converts the image to grayscale.                 #\n",
    "# Second filter detects horizontal edges in the blue channel.             #\n",
    "# Set up the red, green, and blue channels of the filter.                 #\n",
    "###########################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "###########################################################################\n",
    "#                             END OF YOUR CODE                            #\n",
    "###########################################################################        \n",
    "\n",
    "# Vector of biases. We don't need any bias for the grayscale\n",
    "# filter, but for the edge detection filter we want to add 128\n",
    "# to each output so that nothing is negative.\n",
    "b = np.array([0, 128])\n",
    "\n",
    "# Compute the result of convolving each input in x with each filter in w,\n",
    "# offsetting by b, and storing the results in out.\n",
    "out, _ = conv_forward_numpy(x, w, b, {'stride': 1, 'pad': 1})\n",
    "\n",
    "def imshow_no_ax(img, normalize=True):\n",
    "    \"\"\" Tiny helper to show images as uint8 and remove axis labels \"\"\"\n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "# Show the original images and the results of the conv operation\n",
    "plt.subplot(2, 3, 1)\n",
    "imshow_no_ax(puppy, normalize=False)\n",
    "plt.title('Original image')\n",
    "plt.subplot(2, 3, 2)\n",
    "imshow_no_ax(out[0, 0])\n",
    "plt.title('Grayscale')\n",
    "plt.subplot(2, 3, 3)\n",
    "imshow_no_ax(out[0, 1])\n",
    "plt.title('Edges')\n",
    "plt.subplot(2, 3, 4)\n",
    "imshow_no_ax(kitten_cropped, normalize=False)\n",
    "plt.subplot(2, 3, 5)\n",
    "imshow_no_ax(out[1, 0])\n",
    "plt.subplot(2, 3, 6)\n",
    "imshow_no_ax(out[1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dj9_WhwxXdcA"
   },
   "source": [
    "# Im2col Transform\n",
    "\n",
    "Achieving efficiency in convolutional operations is crucial for enhancing the performance of convolutional neural networks. In this exercise, we'll delve into optimizing and parallelizing these operations individually.\n",
    "\n",
    "![Im2col](sjk012/img/im2col.png) \n",
    "\n",
    "Open the file `sjk012/im2col/im2col.pyx` and implement the `im2col` transform using Cython. Remember to parallelize the first loop using OpenMP; you can utilize the `prange` function for this purpose.\n",
    "\n",
    "The `im2col` implementation relies on a Cython extension. To compile it, execute the cell below.\n",
    "\n",
    "Then, you can test its correctness by executing the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pyximport to compile the cython modules\n",
    "import pyximport\n",
    "pyximport.install(reload_support=True, pyimport=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rel errors should be around e-9 or less.\n",
    "from sjk012.im2col.im2col import im2col_cython\n",
    "from time import time\n",
    "\n",
    "x_shape = (2, 3, 4, 4)\n",
    "w_shape = (2, 3, 3, 3)\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "\n",
    "x = np.linspace(-0.1, 0.5, num=np.prod(x_shape), dtype=np.float32).reshape(x_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=np.prod(w_shape), dtype=np.float32).reshape(w_shape)\n",
    "\n",
    "out = im2col_cython(x, w_shape[2], w_shape[3], conv_param['pad'], conv_param['stride'])\n",
    "correct_out = np.array([[ 0.          ,0.          ,0.         ,-0.06842105  ,0.          ,0.          , 0.          ,0.23473684],\n",
    "                        [ 0.          ,0.         ,-0.07473684 ,-0.06210526  ,0.          ,0.          , 0.22842105  ,0.24105263],\n",
    "                        [ 0.          ,0.         ,-0.06842105 ,-0.05578947  ,0.          ,0.          , 0.23473684  ,0.24736843],\n",
    "                        [ 0.         ,-0.09368421  ,0.         ,-0.04315789  ,0.          ,0.20947368  , 0.          ,0.26      ],\n",
    "                        [-0.1        ,-0.08736842 ,-0.04947368 ,-0.0368421   ,0.2031579   ,0.21578947  , 0.25368422  ,0.2663158 ],\n",
    "                        [-0.09368421 ,-0.08105263 ,-0.04315789 ,-0.03052632  ,0.20947368  ,0.22210526  , 0.26        ,0.2726316 ],\n",
    "                        [ 0.         ,-0.06842105  ,0.         ,-0.01789474  ,0.          ,0.23473684  , 0.          ,0.28526315],\n",
    "                        [-0.07473684 ,-0.06210526 ,-0.02421053 ,-0.01157895  ,0.22842105  ,0.24105263  , 0.27894738  ,0.29157895],\n",
    "                        [-0.06842105 ,-0.05578947 ,-0.01789474 ,-0.00526316  ,0.23473684  ,0.24736843  , 0.28526315  ,0.29789475],\n",
    "                        [ 0.          ,0.          ,0.          ,0.03263158  ,0.          ,0.          , 0.          ,0.33578947],\n",
    "                        [ 0.          ,0.          ,0.02631579  ,0.03894737  ,0.          ,0.          , 0.32947367  ,0.34210527],\n",
    "                        [ 0.          ,0.          ,0.03263158  ,0.04526316  ,0.          ,0.          , 0.33578947  ,0.34842107],\n",
    "                        [ 0.          ,0.00736842  ,0.          ,0.05789474  ,0.          ,0.3105263   , 0.          ,0.36105263],\n",
    "                        [ 0.00105263  ,0.01368421  ,0.05157895  ,0.06421053  ,0.3042105   ,0.3168421   , 0.35473683  ,0.36736843],\n",
    "                        [ 0.00736842  ,0.02        ,0.05789474  ,0.07052632  ,0.3105263   ,0.3231579   , 0.36105263  ,0.3736842 ],\n",
    "                        [ 0.          ,0.03263158  ,0.          ,0.0831579   ,0.          ,0.33578947  , 0.          ,0.3863158 ],\n",
    "                        [ 0.02631579  ,0.03894737  ,0.07684211  ,0.08947369  ,0.32947367  ,0.34210527  , 0.38        ,0.3926316 ],\n",
    "                        [ 0.03263158  ,0.04526316  ,0.0831579   ,0.09578948  ,0.33578947  ,0.34842107  , 0.3863158   ,0.39894736],\n",
    "                        [ 0.          ,0.          ,0.          ,0.13368422  ,0.          ,0.          , 0.          ,0.4368421 ],\n",
    "                        [ 0.          ,0.          ,0.12736842  ,0.14        ,0.          ,0.          , 0.43052632  ,0.44315788],\n",
    "                        [ 0.          ,0.          ,0.13368422  ,0.14631578  ,0.          ,0.          , 0.4368421   ,0.44947368],\n",
    "                        [ 0.          ,0.10842105  ,0.          ,0.15894736  ,0.          ,0.41157895  , 0.          ,0.46210527],\n",
    "                        [ 0.10210526  ,0.11473684  ,0.15263158  ,0.16526316  ,0.40526316  ,0.41789475  , 0.45578948  ,0.46842104],\n",
    "                        [ 0.10842105  ,0.12105263  ,0.15894736  ,0.17157894  ,0.41157895  ,0.42421052  , 0.46210527  ,0.47473684],\n",
    "                        [ 0.          ,0.13368422  ,0.          ,0.18421052  ,0.          ,0.4368421   ,  0.         ,0.48736843],\n",
    "                        [ 0.12736842  ,0.14        ,0.17789474  ,0.19052632  ,0.43052632  ,0.44315788  , 0.48105264  ,0.4936842 ],\n",
    "                        [ 0.13368422  ,0.14631578  ,0.18421052  ,0.1968421   ,0.4368421   ,0.44947368  , 0.48736843  ,0.5       ]])\n",
    "\n",
    "# Compare your output to ours; difference should be around e-7\n",
    "print('Testing im2col_cython')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Im2col-based Convolution\n",
    "\n",
    "With the optimized im2col transform, you can now implement the im2col-based convolution function `conv_forward_cython` in the file `sjk012/layers.py`.\n",
    "\n",
    "The following schema illustrates the matrix operations involved in performing the convolution using the im2col transform:\n",
    "\n",
    "![Convolution forward](sjk012/img/conv_forward_im2col.png) \n",
    "\n",
    "The im2col-based convolution involves the following steps:\n",
    "\n",
    "1. **Reshape input data**:\n",
    "   \n",
    "   $$X_{col} = \\text{im2col}(X, R, S, \\text{padding}, \\text{stride})$$\n",
    "\n",
    "2. **Reshape filters**:\n",
    "   \n",
    "   $$W_{row} = \\text{reshape}(W, (K, R \\times S \\times C))$$\n",
    "\n",
    "3. **Perform matrix multiplication**:\n",
    "\n",
    "   $$O = W_{row} \\times X_{col} + b$$\n",
    "\n",
    "4. **Reshape output**:\n",
    "   \n",
    "   $$\\text{output} = \\text{reshape}(O, (N, K, H_o, W_o))$$\n",
    "\n",
    "Implement these steps in the function `conv_forward_cython` to carry out the im2col-based convolution.\n",
    "\n",
    "Once you complete the implementation, you can test its functionality using the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shape = (2, 3, 5, 5)\n",
    "w_shape = (3, 3, 3, 3)\n",
    "x = np.linspace(-0.1, 0.5, num=np.prod(x_shape), dtype=np.float32).reshape(x_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=np.prod(w_shape), dtype=np.float32).reshape(w_shape)\n",
    "b = np.linspace(-0.1, 0.2, num=3, dtype=np.float32)\n",
    "\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "out, _ = conv_forward_cython(x, w, b, conv_param)\n",
    "correct_out = np.array([[[[-0.06974833, -0.06704278, -0.08701342],\n",
    "                          [-0.1167995 , -0.14790688, -0.1481334 ],\n",
    "                          [-0.16322148, -0.21268874, -0.1877349 ]],\n",
    "\n",
    "                         [[ 0.10607383,  0.14003775,  0.11327182],\n",
    "                          [ 0.1636703 ,  0.22531879,  0.16903104],\n",
    "                          [ 0.1349161 ,  0.17786492,  0.13486576]],\n",
    "\n",
    "                         [[ 0.281896  ,  0.34711832,  0.31355706],\n",
    "                          [ 0.44414014,  0.59854448,  0.48619545],\n",
    "                          [ 0.43305367,  0.56841862,  0.45746642]]],\n",
    "\n",
    "\n",
    "                        [[[-0.45481545, -0.6616317 , -0.49473158],\n",
    "                          [-0.74536496, -1.1162374 , -0.81067538],\n",
    "                          [-0.61624163, -0.90920722, -0.66340607]],\n",
    "\n",
    "                         [[ 0.3325839 ,  0.46281463,  0.31713089],\n",
    "                          [ 0.45247066,  0.63303697,  0.42385486],\n",
    "                          [ 0.29347315,  0.39871228,  0.27077183]],\n",
    "\n",
    "                         [[ 1.1199832 ,  1.58726108,  1.12899327],\n",
    "                          [ 1.65030622,  2.38231134,  1.65838516],\n",
    "                          [ 1.20318794,  1.70663178,  1.20494974]]]])\n",
    "\n",
    "# Compare your output to ours; difference should be around e-8\n",
    "print('Testing conv_forward_naive')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Performance Evaluation\n",
    "\n",
    "In this section, we will evaluate the performance of the numpy and im2col-based convolutions using the parallel version.\n",
    "\n",
    "### Task Description\n",
    "\n",
    "1. **Plot Execution Times**: Plot the execution times of both numpy and im2col-based convolutions, varying the number of threads and adjusting parameters such as batch size, number of filters, and input channels.\n",
    "\n",
    "2. **Observations**: Analyze the execution times of each convolution version under different scenarios, considering variations in the batch size, image size, filter size, number of filters, and number of channels.\n",
    "\n",
    "### Observations\n",
    "\n",
    "- **Scalability with Threads**: Determine which version scales better with respect to the number of threads and other parameters.\n",
    "\n",
    "- **Efficiency Comparison**: Assess the efficiency of each convolution version under various scenarios.\n",
    "\n",
    "*Write your observations here:*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threadpoolctl import threadpool_limits\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "# Define matrix sizes\n",
    "image_sizes = [2**i for i in range(4, 7)]\n",
    "\n",
    "# Filter sizes\n",
    "filter_sizes = [3]\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "# Number of repetitions\n",
    "repetitions = 3\n",
    "\n",
    "thread_range = [1, 2, 4, 8, 16, 24]\n",
    "\n",
    "# Initialize arrays to store execution times\n",
    "numpy_times = np.zeros((len(image_sizes), len(filter_sizes), len(thread_range)))\n",
    "cython_times = np.zeros((len(image_sizes), len(filter_sizes), len(thread_range)))\n",
    "\n",
    "for num_threads, n_threads in enumerate(thread_range):\n",
    "    with threadpool_limits(limits=n_threads):\n",
    "        \n",
    "        # Measure performance for each size\n",
    "        for idx_size, size in enumerate(image_sizes):\n",
    "            print(f\"Image size: {size} x {size}, Threads: {n_threads}\")\n",
    "\n",
    "            for idx_filter, filter_size in enumerate(filter_sizes):\n",
    "                # Initialize arrays to store execution times for current size and filter size\n",
    "                numpy_times_size = []\n",
    "                cython_times_size = []\n",
    "                \n",
    "                x = np.random.randn(32, 3, size, size).astype(np.float32)\n",
    "                w = np.random.randn(5, 3, filter_size, filter_size).astype(np.float32)\n",
    "                b = np.random.randn(5).astype(np.float32)\n",
    "\n",
    "                for _ in range(repetitions):\n",
    "                    pass\n",
    "                    ###########################################################################\n",
    "                    # TODO: Call the corresponding versions of the convolution and append the #\n",
    "                    # times to the previously created vectors                                  #\n",
    "                    ###########################################################################\n",
    "                    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "                    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "                    ###########################################################################\n",
    "                    #                             END OF YOUR CODE                            #\n",
    "                    ###########################################################################            \n",
    "\n",
    "                # Compute average execution times for current size, filter size, and number of threads\n",
    "                numpy_times[idx_size, idx_filter, num_threads] = np.mean(numpy_times_size)\n",
    "                cython_times[idx_size, idx_filter, num_threads] = np.mean(cython_times_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting subplots\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8), sharex=True, sharey=True)\n",
    "\n",
    "for i, n_threads in enumerate([1, 2, 4, 8, 16, 24]):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    #axs[row, col].plot(image_sizes, numpy_times[..., i], marker='o', label=f'NumPy')\n",
    "    axs[row, col].plot(image_sizes, cython_times[..., i], marker='.', label=f'Cython')\n",
    "    axs[row, col].set_title(f'Threads: {n_threads}')\n",
    "    axs[row, col].set_xlabel('Matrix size')\n",
    "    axs[row, col].set_ylabel('Execution time (seconds)')\n",
    "    axs[row, col].legend()\n",
    "    axs[row, col].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tJmj2NVZXdb2"
   },
   "source": [
    "# Convolution: Naive Backward Pass\n",
    "\n",
    "![Convolution Backward](sjk012/img/conv_backward.png) \n",
    "\n",
    "To implement the backward pass for the convolution operation, you can utilize the following formulas:\n",
    "\n",
    "1. **Compute the gradient with respect to the input** ($\\nabla X$):\n",
    "\n",
    "$$\\nabla X[c, i, j] = \\sum_{l=0}^{K_h-1} \\sum_{d=0}^{K_w-1} \\sum_{k=0}^{K-1} F[k, c, l, d] \\cdot \\nabla O[k, i+l, j+d]$$\n",
    "\n",
    "2. **Compute the gradient with respect to the filters** ($\\nabla F$):\n",
    "\n",
    "$$\\nabla F[k, l, d] = \\sum_{i=0}^{H_{out}-1} \\sum_{j=0}^{W_{out}-1} \\nabla O[k, i, j] \\cdot X[i+l, j+d]$$\n",
    "\n",
    "3. **Compute the gradient with respect to the bias** ($\\nabla b$):\n",
    "\n",
    "$$\\nabla b = \\sum_{i=0}^{H_{out}-1} \\sum_{j=0}^{W_{out}-1} \\nabla O[:, i, j]$$\n",
    "\n",
    "\n",
    "Implement these calculations in the function `conv_backward_numpy` within the file `sjk012/layers.py`. Don't worry too much about computational efficiency at this stage.\n",
    "\n",
    "After implementation, run the following code to verify your backward pass with a numeric gradient check.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1629831289227,
     "user": {
      "displayName": "MANTAS BIRŠKUS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p74VzcLbLKZFYUnmVzxKmHhFZC9ouHcczEsEmQ=s64",
      "userId": "00995227095641424292"
     },
     "user_tz": -180
    },
    "id": "DC97HqAwXdb6",
    "outputId": "d5c0f0ec-ca66-4dec-cd2f-129bf4125b47"
   },
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "x = np.random.randn(4, 3, 5, 5).astype(np.float32)\n",
    "w = np.random.randn(2, 3, 3, 3).astype(np.float32)\n",
    "b = np.random.randn(2,).astype(np.float32)\n",
    "dy = np.random.randn(4, 2, 5, 5).astype(np.float32)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_forward_numpy(x, w, b, conv_param)[0], x, dy, h=1e-2)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_forward_numpy(x, w, b, conv_param)[0], w, dy, h=1e-2)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_forward_numpy(x, w, b, conv_param)[0], b, dy, h=1e-2)\n",
    "\n",
    "out, cache = conv_forward_numpy(x, w, b, conv_param)\n",
    "dx, dw, db = conv_backward_numpy(dy, cache)\n",
    "\n",
    "# Your errors should be around e-3 or less.\n",
    "print('Testing conv_backward_naive function')\n",
    "print('dx error: ', rel_error(dx, dx_num))\n",
    "print('dw error: ', rel_error(dw, dw_num))\n",
    "print('db error: ', rel_error(db, db_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dj9_WhwxXdcA"
   },
   "source": [
    "# Col2im transform\n",
    "\n",
    "In this exercise we will learn to individually optimise and parallelise the backward convolution using the col2im transform, which corresponds to the inverse of the im2col.\n",
    "\n",
    "![col2im](sjk012/img/col2im.gif)\n",
    "\n",
    "Open the `sjk012/col2im/col2im.pyx` and implement the col2im transform using Cython. Remember to parallelise the first loop using OpenMP, use the `prange` function.\n",
    "\n",
    "The im2col implementation depends on a Cython extension; to compile it, run the cell below. Next, save the Colab notebook (`File > Save`) and **restart the runtime** (`Runtime > Restart runtime`). You can then re-execute the preceeding cells from top to bottom and skip the cell below as you only need to run it once for the compilation step.\n",
    "\n",
    "Once you are done, you can test the correct workings executing this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rel errors should be around e-9 or less.\n",
    "from sjk012.col2im.col2im import col2im_cython\n",
    "from time import time\n",
    "\n",
    "x_shape = (2, 3, 4, 4)\n",
    "w_shape = (2, 3, 3, 3)\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "\n",
    "cols_output = np.array([[ 0.          ,0.          ,0.         ,-0.06842105  ,0.          ,0.          , 0.          ,0.23473684],\n",
    "                        [ 0.          ,0.         ,-0.07473684 ,-0.06210526  ,0.          ,0.          , 0.22842105  ,0.24105263],\n",
    "                        [ 0.          ,0.         ,-0.06842105 ,-0.05578947  ,0.          ,0.          , 0.23473684  ,0.24736843],\n",
    "                        [ 0.         ,-0.09368421  ,0.         ,-0.04315789  ,0.          ,0.20947368  , 0.          ,0.26      ],\n",
    "                        [-0.1        ,-0.08736842 ,-0.04947368 ,-0.0368421   ,0.2031579   ,0.21578947  , 0.25368422  ,0.2663158 ],\n",
    "                        [-0.09368421 ,-0.08105263 ,-0.04315789 ,-0.03052632  ,0.20947368  ,0.22210526  , 0.26        ,0.2726316 ],\n",
    "                        [ 0.         ,-0.06842105  ,0.         ,-0.01789474  ,0.          ,0.23473684  , 0.          ,0.28526315],\n",
    "                        [-0.07473684 ,-0.06210526 ,-0.02421053 ,-0.01157895  ,0.22842105  ,0.24105263  , 0.27894738  ,0.29157895],\n",
    "                        [-0.06842105 ,-0.05578947 ,-0.01789474 ,-0.00526316  ,0.23473684  ,0.24736843  , 0.28526315  ,0.29789475],\n",
    "                        [ 0.          ,0.          ,0.          ,0.03263158  ,0.          ,0.          , 0.          ,0.33578947],\n",
    "                        [ 0.          ,0.          ,0.02631579  ,0.03894737  ,0.          ,0.          , 0.32947367  ,0.34210527],\n",
    "                        [ 0.          ,0.          ,0.03263158  ,0.04526316  ,0.          ,0.          , 0.33578947  ,0.34842107],\n",
    "                        [ 0.          ,0.00736842  ,0.          ,0.05789474  ,0.          ,0.3105263   , 0.          ,0.36105263],\n",
    "                        [ 0.00105263  ,0.01368421  ,0.05157895  ,0.06421053  ,0.3042105   ,0.3168421   , 0.35473683  ,0.36736843],\n",
    "                        [ 0.00736842  ,0.02        ,0.05789474  ,0.07052632  ,0.3105263   ,0.3231579   , 0.36105263  ,0.3736842 ],\n",
    "                        [ 0.          ,0.03263158  ,0.          ,0.0831579   ,0.          ,0.33578947  , 0.          ,0.3863158 ],\n",
    "                        [ 0.02631579  ,0.03894737  ,0.07684211  ,0.08947369  ,0.32947367  ,0.34210527  , 0.38        ,0.3926316 ],\n",
    "                        [ 0.03263158  ,0.04526316  ,0.0831579   ,0.09578948  ,0.33578947  ,0.34842107  , 0.3863158   ,0.39894736],\n",
    "                        [ 0.          ,0.          ,0.          ,0.13368422  ,0.          ,0.          , 0.          ,0.4368421 ],\n",
    "                        [ 0.          ,0.          ,0.12736842  ,0.14        ,0.          ,0.          , 0.43052632  ,0.44315788],\n",
    "                        [ 0.          ,0.          ,0.13368422  ,0.14631578  ,0.          ,0.          , 0.4368421   ,0.44947368],\n",
    "                        [ 0.          ,0.10842105  ,0.          ,0.15894736  ,0.          ,0.41157895  , 0.          ,0.46210527],\n",
    "                        [ 0.10210526  ,0.11473684  ,0.15263158  ,0.16526316  ,0.40526316  ,0.41789475  , 0.45578948  ,0.46842104],\n",
    "                        [ 0.10842105  ,0.12105263  ,0.15894736  ,0.17157894  ,0.41157895  ,0.42421052  , 0.46210527  ,0.47473684],\n",
    "                        [ 0.          ,0.13368422  ,0.          ,0.18421052  ,0.          ,0.4368421   ,  0.         ,0.48736843],\n",
    "                        [ 0.12736842  ,0.14        ,0.17789474  ,0.19052632  ,0.43052632  ,0.44315788  , 0.48105264  ,0.4936842 ],\n",
    "                        [ 0.13368422  ,0.14631578  ,0.18421052  ,0.1968421   ,0.4368421   ,0.44947368  , 0.48736843  ,0.5       ]], \n",
    "                       dtype=np.float32)\n",
    "\n",
    "out = np.array([[[[-1.0000000e-01, -1.8736842e-01, -8.7368421e-02, -8.1052631e-02],\n",
    "                  [-1.4947368e-01, -2.7368420e-01, -1.2421052e-01, -1.1157894e-01],\n",
    "                  [-4.9473681e-02, -8.6315781e-02, -3.6842100e-02, -3.0526320e-02],\n",
    "                  [-2.4210529e-02, -3.5789479e-02, -1.1578950e-02, -5.2631600e-03]],\n",
    "\n",
    "                 [[ 1.0526300e-03,  1.4736840e-02,  1.3684210e-02,  2.0000000e-02],\n",
    "                  [ 5.2631579e-02,  1.3052632e-01,  7.7894740e-02,  9.0526320e-02],\n",
    "                  [ 5.1578950e-02,  1.1578948e-01,  6.4210527e-02,  7.0526317e-02],\n",
    "                  [ 7.6842107e-02,  1.6631579e-01,  8.9473687e-02,  9.5789477e-02]],\n",
    "\n",
    "                 [[ 1.0210526e-01,  2.1684210e-01,  1.1473684e-01,  1.2105263e-01],\n",
    "                  [ 2.5473684e-01,  5.3473687e-01,  2.8000000e-01,  2.9263157e-01],\n",
    "                  [ 1.5263158e-01,  3.1789473e-01,  1.6526316e-01,  1.7157894e-01],\n",
    "                  [ 1.7789474e-01,  3.6842105e-01,  1.9052632e-01,  1.9684210e-01]]],\n",
    "\n",
    "\n",
    "                [[[ 2.0315790e-01,  4.1894737e-01,  2.1578947e-01,  2.2210526e-01],\n",
    "                  [ 4.5684209e-01,  9.3894738e-01,  4.8210526e-01,  4.9473685e-01],\n",
    "                  [ 2.5368422e-01,  5.1999998e-01,  2.6631579e-01,  2.7263159e-01],\n",
    "                  [ 2.7894738e-01,  5.7052630e-01,  2.9157895e-01,  2.9789475e-01]],\n",
    "\n",
    "                 [[ 3.0421051e-01,  6.2105262e-01,  3.1684211e-01,  3.2315791e-01],\n",
    "                  [ 6.5894735e-01,  1.3431579e+00,  6.8421054e-01,  6.9684213e-01],\n",
    "                  [ 3.5473683e-01,  7.2210526e-01,  3.6736843e-01,  3.7368420e-01],\n",
    "                  [ 3.8000000e-01,  7.7263159e-01,  3.9263159e-01,  3.9894736e-01]],\n",
    "\n",
    "                 [[ 4.0526316e-01,  8.2315791e-01,  4.1789475e-01,  4.2421052e-01],\n",
    "                  [ 8.6105263e-01,  1.7473685e+00,  8.8631576e-01,  8.9894736e-01],\n",
    "                  [ 4.5578948e-01,  9.2421055e-01,  4.6842104e-01,  4.7473684e-01],\n",
    "                  [ 4.8105264e-01,  9.7473687e-01,  4.9368420e-01,  5.0000000e-01]]]])\n",
    "\n",
    "out_col2im = col2im_cython(cols_output, x_shape[0], x_shape[1], x_shape[2], x_shape[3], w_shape[2], \n",
    "                    w_shape[3], conv_param['pad'], conv_param['stride'])\n",
    "\n",
    "# Compare your output to ours; difference should be around e-7\n",
    "print('Testing im2col_cython')\n",
    "print('difference: ', rel_error(out, out_col2im))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Col2im-based Backward Convolution\n",
    "\n",
    "With the optimized col2im transform, you can now implement the col2im-based convolution function `conv_backward_cython` in the file `sjk012/fast_layers.py`. Refer to the matrix view in the picture for a visualization of the operation.\n",
    "\n",
    "![Convolution Backward Col2im](sjk012/img/conv_backward_im2col.png) \n",
    "\n",
    "The col2im-based backward convolution involves the following steps:\n",
    "\n",
    "1. **Transpose and reshape output gradient**:\n",
    "   \n",
    "   $$\\nabla Y_{cols} = \\text{reshape}(\\text{transpose}(\\nabla Y, K, N, H_{out}, W_{out}), (K, N \\times H_{out} \\times W_{out}))$$\n",
    "\n",
    "2. **Compute gradient with respect to filters**:\n",
    "   \n",
    "   $$\\nabla F = \\text{reshape}(Y_{cols} \\times X_{cols}^T, (K, C, R, S))$$\n",
    "\n",
    "3. **Compute gradient with respect to biases**:\n",
    "   \n",
    "   $$\\nabla b = \\text{reduce\\_sum}(\\nabla Y, axis=(N, H_{out}, W_{out}))$$\n",
    "      \n",
    "4. **Compute gradient with respect to inputs**:\n",
    "\n",
    "   $$\\nabla X_{cols} = \\text{reshape}(W, (K, C, R, S)) ^ T \\times \\nabla Y_{cols}$$\n",
    "\n",
    "5. **Convert $\\nabla X_{cols}$ gradient to image format**:\n",
    "   \n",
    "   $$\\nabla X = \\text{col2im}(\\nabla X_{cols}, N, C, H, W, R, S, padding, stride)$$\n",
    "\n",
    "\n",
    "Implement these steps in the function `conv_backward_cython` to carry out the col2im-based backward convolution.\n",
    "\n",
    "Once you complete the implementation, you can test its functionality using the provided code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1629831289227,
     "user": {
      "displayName": "MANTAS BIRŠKUS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p74VzcLbLKZFYUnmVzxKmHhFZC9ouHcczEsEmQ=s64",
      "userId": "00995227095641424292"
     },
     "user_tz": -180
    },
    "id": "DC97HqAwXdb6",
    "outputId": "d5c0f0ec-ca66-4dec-cd2f-129bf4125b47"
   },
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "x = np.random.randn(4, 3, 5, 5).astype(np.float32)\n",
    "w = np.random.randn(2, 3, 3, 3).astype(np.float32)\n",
    "b = np.random.randn(2,).astype(np.float32)\n",
    "dy = np.random.randn(4, 2, 5, 5).astype(np.float32)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_forward_cython(x, w, b, conv_param)[0], x, dy, h=1e-2)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_forward_cython(x, w, b, conv_param)[0], w, dy, h=1e-2)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_forward_cython(x, w, b, conv_param)[0], b, dy, h=1e-2)\n",
    "\n",
    "out, cache = conv_forward_cython(x, w, b, conv_param)\n",
    "dx, dw, db = conv_backward_cython(dy, cache)\n",
    "\n",
    "# Your errors should be around e-3 or less.\n",
    "print('Testing conv_backward_naive function')\n",
    "print('dx error: ', rel_error(dx, dx_num))\n",
    "print('dw error: ', rel_error(dw, dw_num))\n",
    "print('db error: ', rel_error(db, db_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation\n",
    "\n",
    "It's time to evaluate the performance and accuracy of convolution functions using both numpy and Cython implementations. \n",
    "\n",
    "This experiment measures the time taken for both forward and backward passes of convolution operations and compares them. \n",
    "\n",
    "Additionally, it checks the correctness of the Cython implementation by comparing the results with the numpy implementation, ensuring minimal relative errors. \n",
    "\n",
    "The aim is to verify the efficiency and accuracy of the Cython implementation compared to the numpy baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 902,
     "status": "ok",
     "timestamp": 1629831360678,
     "user": {
      "displayName": "MANTAS BIRŠKUS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p74VzcLbLKZFYUnmVzxKmHhFZC9ouHcczEsEmQ=s64",
      "userId": "00995227095641424292"
     },
     "user_tz": -180
    },
    "id": "zDSi4Gg6XdcE",
    "outputId": "bb6a2d12-301b-42bf-cbd4-685885986988"
   },
   "outputs": [],
   "source": [
    "# Rel errors should be around e-9 or less.\n",
    "from time import time\n",
    "\n",
    "np.random.seed(12)\n",
    "x = np.random.randn(100, 3, 31, 31).astype(np.float32)\n",
    "w = np.random.randn(25, 3, 3, 3).astype(np.float32)\n",
    "b = np.random.randn(25,).astype(np.float32)\n",
    "dy = np.random.randn(100, 25, 16, 16).astype(np.float32)\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "\n",
    "t0 = time()\n",
    "out_numpy, cache_numpy = conv_forward_numpy(x, w, b, conv_param)\n",
    "t1 = time()\n",
    "out_cython, cache_cython = conv_forward_cython(x, w, b, conv_param)\n",
    "t2 = time()\n",
    "\n",
    "print('Testing conv_forward_cython:')\n",
    "print('Numpy: %fs' % (t1 - t0))\n",
    "print('Cython: %fs' % (t2 - t1))\n",
    "print('Speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('Difference: ', rel_error(out_numpy, out_cython))\n",
    "\n",
    "t0 = time()\n",
    "dx_numpy, dw_numpy, db_numpy = conv_backward_numpy(dy, cache_numpy)\n",
    "t1 = time()\n",
    "dx_cython, dw_cython, db_cython = conv_backward_cython(dy, cache_cython)\n",
    "t2 = time()\n",
    "\n",
    "print('\\nTesting conv_backward_cython:')\n",
    "print('Numpy: %fs' % (t1 - t0))\n",
    "print('Cython: %fs' % (t2 - t1))\n",
    "print('Speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('dx difference: ', rel_error(dx_numpy, dx_cython))\n",
    "print('dw difference: ', rel_error(dw_numpy, dw_cython))\n",
    "print('db difference: ', rel_error(db_numpy, db_cython))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQXlLAiCXdb7"
   },
   "source": [
    "# Max-Pooling: Naive Forward Pass\n",
    "\n",
    "![Max-Pooling](sjk012/img/maxpool.gif) \n",
    "\n",
    "Implement the forward pass for the max-pooling operation in the function `max_pool_forward_naive` in the file `sjk012/layers.py`. Again, don't worry too much about computational efficiency.\n",
    "\n",
    "Check your implementation by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1629909450953,
     "user": {
      "displayName": "MANTAS BIRŠKUS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p74VzcLbLKZFYUnmVzxKmHhFZC9ouHcczEsEmQ=s64",
      "userId": "00995227095641424292"
     },
     "user_tz": -180
    },
    "id": "9s1qJryiXdb9",
    "outputId": "ef8b0196-334a-47cf-d520-0d54173f56ac"
   },
   "outputs": [],
   "source": [
    "x_shape = (2, 3, 4, 4)\n",
    "x = np.linspace(-0.3, 0.4, num=np.prod(x_shape), dtype=np.float32).reshape(x_shape)\n",
    "pool_param = {'pool_width': 2, 'pool_height': 2, 'stride': 2, 'padding': 0}\n",
    "\n",
    "out, _ = max_pool_forward_numpy(x, pool_param)\n",
    "\n",
    "correct_out = np.array([[[[-0.26315789, -0.24842105],\n",
    "                          [-0.20421053, -0.18947368]],\n",
    "                         [[-0.14526316, -0.13052632],\n",
    "                          [-0.08631579, -0.07157895]],\n",
    "                         [[-0.02736842, -0.01263158],\n",
    "                          [ 0.03157895,  0.04631579]]],\n",
    "                        [[[ 0.09052632,  0.10526316],\n",
    "                          [ 0.14947368,  0.16421053]],\n",
    "                         [[ 0.20842105,  0.22315789],\n",
    "                          [ 0.26736842,  0.28210526]],\n",
    "                         [[ 0.32631579,  0.34105263],\n",
    "                          [ 0.38526316,  0.4       ]]]])\n",
    "\n",
    "# Compare your output with ours. Difference should be on the order of e-8.\n",
    "print('Testing max_pool_forward_naive function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max-Pooling: Efficient Forward Pass\n",
    "\n",
    "In this exercise you have to implement a Cython-based max that utilizes the im2col technique implicitly to calculate the maximum value per column without explicitly calling im2col and computing the maximum component per column.\n",
    "\n",
    "Steps in the Cython Implementation:\n",
    "\n",
    "1. **Create Overlapping Patches**: Similar to the im2col method, divide the input data into overlapping patches (1 per channel) based on the pooling window size and stride.\n",
    "\n",
    "2. **Find Maximum Value per Column**: Instead of reshaping patches into a 2D matrix, iterate over each patch and compute the maximum value per column directly.\n",
    "\n",
    "3. **Efficient Calculation**: Utilize Cython to optimize the computation, taking advantage of parallel loops.\n",
    "\n",
    "By using this Cython implementation, we can achieve the same efficiency as the im2col method while avoiding the overhead of explicitly transforming the input data into a 2D matrix. This approach enables faster computation of the max-pooling operation, making it suitable for modern multi-core architectures.\n",
    "\n",
    "Implement the function `max_pooling_cython` in the `layers.py` file. This function should call the Cython implementation provided in `sjk012/max_pool/maxpool_fwd.pyx`. After implementing this function, students can test its correctness by executing the provided code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1629909450953,
     "user": {
      "displayName": "MANTAS BIRŠKUS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p74VzcLbLKZFYUnmVzxKmHhFZC9ouHcczEsEmQ=s64",
      "userId": "00995227095641424292"
     },
     "user_tz": -180
    },
    "id": "9s1qJryiXdb9",
    "outputId": "ef8b0196-334a-47cf-d520-0d54173f56ac"
   },
   "outputs": [],
   "source": [
    "x_shape = (2, 3, 4, 4)\n",
    "x = np.linspace(-0.3, 0.4, num=np.prod(x_shape), dtype=np.float32).reshape(x_shape)\n",
    "pool_param = {'pool_width': 2, 'pool_height': 2, 'stride': 2, 'padding': 0}\n",
    "\n",
    "out, _ = max_pool_forward_cython(x, pool_param)\n",
    "\n",
    "correct_out = np.array([[[[-0.26315789, -0.24842105],\n",
    "                          [-0.20421053, -0.18947368]],\n",
    "                         [[-0.14526316, -0.13052632],\n",
    "                          [-0.08631579, -0.07157895]],\n",
    "                         [[-0.02736842, -0.01263158],\n",
    "                          [ 0.03157895,  0.04631579]]],\n",
    "                        [[[ 0.09052632,  0.10526316],\n",
    "                          [ 0.14947368,  0.16421053]],\n",
    "                         [[ 0.20842105,  0.22315789],\n",
    "                          [ 0.26736842,  0.28210526]],\n",
    "                         [[ 0.32631579,  0.34105263],\n",
    "                          [ 0.38526316,  0.4       ]]]])\n",
    "\n",
    "# Compare your output with ours. Difference should be on the order of e-8.\n",
    "print('Testing max_pool_forward_naive function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHJujXW7Xdb-"
   },
   "source": [
    "# Max-Pooling: Naive Backward\n",
    "Implement the backward pass for the max-pooling operation in the function `max_pool_backward_naive` in the file `sjk012/layers.py`. You don't need to worry about computational efficiency.\n",
    "\n",
    "Check your implementation with numeric gradient checking by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1629915401805,
     "user": {
      "displayName": "MANTAS BIRŠKUS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p74VzcLbLKZFYUnmVzxKmHhFZC9ouHcczEsEmQ=s64",
      "userId": "00995227095641424292"
     },
     "user_tz": -180
    },
    "id": "Shja42VQXdb_",
    "outputId": "abc13747-2e13-428a-a4df-534196e4365a"
   },
   "outputs": [],
   "source": [
    "# Rel errors should be around e-9 or less.\n",
    "np.random.seed(12)\n",
    "x = np.random.randn(3, 2, 8, 8).astype(np.float32)\n",
    "dy = np.random.randn(3, 2, 4, 4).astype(np.float32)\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: max_pool_forward_numpy(x, pool_param)[0], x, dy, h=1e-2)\n",
    "\n",
    "out, cache = max_pool_forward_numpy(x, pool_param)\n",
    "dx = max_pool_backward_numpy(dy, cache)\n",
    "\n",
    "# Your error should be on the order of e-7\n",
    "print('Testing max_pool_backward_naive function:')\n",
    "print('dx error: ', rel_error(dx, dx_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation\n",
    "\n",
    "It's time to evaluate the performance and accuracy of convolution functions using both numpy and Cython implementations. \n",
    "\n",
    "This experiment measures the time taken for both forward and backward passes of convolution operations and compares them. \n",
    "\n",
    "Additionally, it checks the correctness of the Cython implementation by comparing the results with the numpy implementation, ensuring minimal relative errors. \n",
    "\n",
    "The aim is to verify the efficiency and accuracy of the Cython implementation compared to the numpy baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 842,
     "status": "ok",
     "timestamp": 1629831414480,
     "user": {
      "displayName": "MANTAS BIRŠKUS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p74VzcLbLKZFYUnmVzxKmHhFZC9ouHcczEsEmQ=s64",
      "userId": "00995227095641424292"
     },
     "user_tz": -180
    },
    "id": "bbvEdDHyXdcG",
    "outputId": "f6713fa4-e366-48aa-8836-3b2a7f69a555"
   },
   "outputs": [],
   "source": [
    "# Rel errors should be around e-9 or less.\n",
    "np.random.seed(12)\n",
    "x = np.random.randn(100, 3, 32, 32).astype(np.float32)\n",
    "dy = np.random.randn(100, 3, 16, 16).astype(np.float32)\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2, 'padding': 0}\n",
    "\n",
    "t0 = time()\n",
    "out_numpy, cache_numpy = max_pool_forward_numpy(x, pool_param)\n",
    "t1 = time()\n",
    "out_cython, cache_cython = max_pool_forward_cython(x, pool_param)\n",
    "t2 = time()\n",
    "\n",
    "print('Testing max_pool_forward_cython:')\n",
    "print('Numpy: %fs' % (t1 - t0))\n",
    "print('Cython: %fs' % (t2 - t1))\n",
    "print('speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('difference: ', rel_error(out_numpy, out_cython))\n",
    "\n",
    "t0 = time()\n",
    "dx_numpy = max_pool_backward_numpy(dy, cache_numpy)\n",
    "t1 = time()\n",
    "dx_cython = max_pool_backward_cython(dy, cache_cython)\n",
    "t2 = time()\n",
    "\n",
    "print('\\nTesting max_pool_backward_cython:')\n",
    "print('Numpy: %fs' % (t1 - t0))\n",
    "print('Cython: %fs' % (t2 - t1))\n",
    "print('speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('dx difference: ', rel_error(dx_numpy, dx_cython))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ConvolutionalNetworks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
